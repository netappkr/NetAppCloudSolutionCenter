# Harvest and Grafana Installation/Configuration Guide

### Harvest란 무엇인가요?

ONTAP과 StorageGRID 클러스터의 상태를 관찰하기 위해 NetApp 엔지니어들이 개발한 오픈소스 툴입니다. Harvest는 성능, 용량, 하드웨어 상태 등과 같은 메트릭을 수집해 일반 사용자가 이해하기 쉽도록 변환하고 시계열 데이터베이스에 저장할 수 있습니다.



Harvest는 데이터센터 모니터링을 위해 대중적으로 사용되는 Grafana 대시보드를 지원하고 있으며 기본적으로 제공되는 템플릿은 코어 유저에게 필요한 대부분의 정보를 제공합니다. 하지만ONTAP이 지원하는 3000개 이상의 API 호출에 대해 Harvest가 대응하고 있지 않은 API가 있으므로 추가적으로 필요한 메트릭이 있다면 개발을 통해 요구사항에 맞게 제공할 수 있습니다.



### 시스템 요구사항

Harvest는 Go 언어로 작성되어 Linux 또는 macOS에서 개발/구동할 수 있습니다. Harvest를 구동하기 위해 요구되는 시스템 성능은 모니터링 하는 클러스터 수, 수집 메트릭 정보, 수집 주기에 따라 크게 달라집니다. 아래는 클러스터 10대를 수집한다고 가정했을 때 대략적으로 요구되는 시스템입니다.

- OS: Linux (Redhat 또는 Debian 계열 권장), macOS
- CPU: 2 cores
- Memory: 1 GB
- Disk: 500 MB (대부분 로그 저장공간으로 사용 됨)

### 필요 패키지

- Prometheus: 2.26 or higher
- InfluxDB: v2
- Grafana: 8.1.X or higher
- Docker: 20.10.0 or higher

### 설치방법

Harvest는 크게 3가지 방식으로 설치할 수 있습니다.

1. **Package Installation (Redhat .rpm, Debian .deb 지원)**

장점: 확장성

단점: 패키지 Import 및 설치 필요, Redhat, Debian 계열 Linux 필요

2. **Container Installation**

장점: 확장성, 편리함

단점: Docker Image Import 또는 Repo Access 필요, Docker 필요

3. **NABOX**

장점: 이미 구성이 완료 된 OVA 이미지를 사용하므로 가장 편리함

단점: 확장성 낮음 (추후 기술), 별도의 VM을 구동해야 함




일반적으로 별도의 독립된 VM을 구동할 수 있고 클러스터가 소규모인 경우 3번 방식을 권장합니다. 하지만 대규모 클러스터(300대 이상 또는 실시간 성능 모니터링)을 모니터링 해야 하는 환경인 경우 3번 방식은 Prometheus의 제약으로 인해 어렵습니다.

독립 VM을 구동할 수 없는 환경인 경우, 사용하는 Linux 또는 Docker 사용 여부에 따라 1번 또는 2번 방식을 사용할 수 있습니다.

I. ### Package Installation (Redhat 기준)
1. **Harvest Package를 Github Repo에서 받아옵니다**.

버전은 달라질 수 있으므로 최신 버전을 확인해 .rpm 패키지를 다운로드 합니다. ( https://github.com/NetApp/harvest/releases)

```
wget https://github.com/NetApp/harvest/releases/download/v22.08.0/harvest-22.08.0-1.x86_64.rpm
```

2. **Harvest 패키지를 설치합니다.**

```
 sudo yum install harvest-22.08.0-1.x86_64.rpm
```

3. **Harvest의 Config를 수정합니다. 이는 Prometheus Export 포트와 수집해오는 ONTAP 장비를 지정하기 위한 설정입니다.**

```
vim /opt/harvest/harvest.yml
```

아래 2 파트 수정/추가

### Exporter 포트

```yaml
Exporters:
  prom-prod:
    exporter: Prometheus
    port_range: 9000-10000
```

> ### Tips<br>버전이 22.11로 오면서 없어진 옵션들이 있습니다.<br>prometheus\_port , autostart 등등 자세한 내용은 22.11 version 문서를 확인하세요.
> [https://netapp.github.io/harvest/22.11/configure-harvest-basic/](https://netapp.github.io/harvest/22.11/configure-harvest-basic/)

**수집 ONTAP 장비**

```yaml
  tnas0102:
    exporters:
      - prom-prod
    addr: 10.50.10.238
    autostart: '1'
    datacenter: NCP-LAB
    username: admin
    password: Netapp1!
    prometheus_port: 12990
    use_insecure_tls: true
```

- **ONTAP에서 API 권한 추가하기**

Harvest가 ONTAP에서 ZAPI 또는 REST API를 통해 메트릭을 불러오기 위해서는 별도의 권한 설정이 필요합니다. ID/PW 방식을 사용할 수 있고, Certification 방식을 사용할 수 있습니다.

가장 간단한 방법은 ID/PW를 사용하는 방식인데 admin을 사용하면 모든 권한이 있어 바로 사용할 수 있지만 ```least privilege access principle```에 맞지 않기 때문에 별도의 유저를 생성합니다.

https://netapp.github.io/harvest/prepare-cdot-clusters/ 에 ONTAP CLI: Least-privilege approach 부문을 참조하시면 API Call에 필요한 Command 별로 유저 권한을 생성할 수 있고 Read-only로 전체 권한을 줄 수 있습니다.



사용 요건에 따라서 적절한 권한을 부여한 계정을 만들고 3번 과정에 username/password에 해당 계정을 기입하면 됩니다.

> ### Tips
> REST API 사용하는 rest, restperf, ems 등과 같은 collector를 사용할 경우 REST에 해당되는 적절한 권한을 부여해야 합니다!
> ```bash
> Exporters:
>   prometheus:
>     exporter: Prometheus
>     local_http_addr: 0.0.0.0
>     #port: 12990
>     port_range: 13000-14000
>   #prometheus1:
>     #exporter: Prometheus
>     #port_range: 13000-14000
> 
> Defaults:
>   collectors:
>     - Zapi
>     - ZapiPerf
>     - Ems
>     - Rest
>     - RestPerf
>   use_insecure_tls: false
> ```




4. **Harvest 서비스를 시작하고 상태를 확인합니다.**

```
cd /opt/harvest
systemctl start harvest
bin/harvest start
bin/harvest status
```

5. **Grafana가 Harvest 패키지에 포함돼있지 않기 때문에 이를 설치합니다. Grafana Repo를 yum에 추가하고 yum으로 설치합니다.**

```
sudo vi /etc/yum.repos.d/grafana.repo
```

<아래 내용 추가>

```
[grafana]
name=grafana
baseurl=https://rpm.grafana.com
repo_gpgcheck=1
enabled=1
gpgcheck=1
gpgkey=https://rpm.grafana.com/gpg.key
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
```

<설치 후 활성화>

```
sudo yum install grafana
systemctl enable grafana-server
```

6. **Grafana Web 인터페이스가 사용하고자 하는 포트로 변경합니다**.

Reverse Proxy(NGINX 등) 위에 Grafana를 올리려는 경우 원하는 임의의 포트로 지정하고 아니라면 80으로 설정합니다. HTTPS 사용의 경우 해당 Config에서 별도 설정이 필요합니다.


```
vi /etc/grafana/grafana.ini 
```

```
# The http port  to use
http_port = 80
```

7. **Grafana 서비스를 시작합니다.**
위 7번에서 포트를 1000 이하로 설정한 경우 Grafana User 권한의 문제로 서비스가 실패합니다.
여러 해결방법이 있지만 예시로8번 과정을 수행합니다.

```
 systemctl start grafana-server.serivce
```

8. **권한 이슈 해결방법**

```
sudo vim /usr/lib/systemd/system/grafana-server.service
```

- \[Service\] 파트 맨 아래 추가

```
CapabilityBoundingSet=CAP_NET_BIND_SERVICE
AmbientCapabilities=CAP_NET_BIND_SERVICE
PrivateUsers=false
```

- 서비스를 재시작합니다.

```
systemctl daemon-reload
systemctl stop grafana-server.service
systemctl start grafana-server
```

9. **RedHat 기준으로 80/443/9090 포트 오픈 방법입니다. 9090은 추후 Prometheus Web Interface 접근용으로 오픈합니다.**

```
firewall-cmd --permanent --zone=public --add-service=http
firewall-cmd --permanent --zone=public --add-service=https
firewall-cmd --permanent --zone=public --add-port=9090/tcp
firewall-cmd --reload
```

Grafana Web 서버가 정상적으로 수행되면 아래 명령어의 결과로 확인할 수 있습니다.

Default ID/PW : admin:admin

```
 ss -antpl | grep 80
```

![](image_1.53e22540.png)



Prometheus를 설치합니다.

10. **Prometheus를 설치합니다.**

**Docker로 설치해도 되고 Package 방식으로 해도 됩니다.**




- **Prometheus를 다운로드하고 압축을 해제합니다.**

```
wget https://github.com/prometheus/prometheus/releases/download/v2.40.1/prometheus-2.40.1.linux-amd64.tar.gz
tar -xvf prometheus-2.40.1.linux-amd64.tar.gz 
mv prometheus-2.40.1.linux-amd64 prometheus
```

- **필요한 유저 권한과 경로를 생성합니다.**

```
sudo useradd --no-create-home --shell /bin/false prometheus
sudo mkdir /etc/prometheus
sudo mkdir /var/lib/prometheus
sudo chown prometheus:prometheus /etc/prometheus
sudo chown prometheus:prometheus /var/lib/prometheus
```



- **실행에 필요한 Binary를 복사하고 권한을 수정합니다.**

```
sudo cp prometheus/prometheus /usr/local/bin/
sudo cp prometheus/promtool /usr/local/bin/
sudo chown prometheus:prometheus /usr/local/bin/prometheus
sudo chown prometheus:prometheus /usr/local/bin/promtool
sudo cp -r prometheus/consoles /etc/prometheus
sudo cp -r prometheus/console_libraries /etc/prometheus
sudo chown -R prometheus:prometheus /etc/prometheus/consoles
sudo chown -R prometheus:prometheus /etc/prometheus/console_libraries
```



- **Config 파일을 생성합니다.**

```
 sudo vi /etc/prometheus/prometheus.yml
```

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9000'] <- 3번 과정에서 Exporter의 포트를 입력합니다. 예시 기준으로Poller가 1개라면 9000입니다.
```



아래와 같은 명령어를 실행했을 때 확인되는 PromPort가 Exporter 포트입니다.



![](image_2.4ac9c251.png)





- **Config의 권한을 변경합니다.**

```
 sudo chown prometheus:prometheus /etc/prometheus/prometheus.yml
```

- **자동 실행을 위해 Service를 만들고 실행합니다.
ExecStart에서 Retention Time과 같이 필요한 변수를 조정합니다.**

```
 sudo vi /etc/systemd/system/prometheus.service
```

```
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file /etc/prometheus/prometheus.yml \
    --storage.tsdb.path /var/lib/prometheus/ \
    --storage.tsdb.retention.time=1y \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries
[Install]
WantedBy=multi-user.target
```

```
sudo systemctl daemon-reload
sudo systemctl enable prometheus
sudo systemctl start prometheus
sudo systemctl status prometheus
```

> ### Tips
> ## Prometheus 저장소 구성 설정
> Prometheus의 데이터 저장소를 구성하는 설정 중 중요한 것은 아래와 같다.
> 1.```--storage.tsdb.path : Prometheus```의 데이터베이스 경로. 기본값은 /data이다.
> 2. ```--storage.tsdb.retention.time``` : 데이터 보관기간. 기본값은 15일이다.
> 3. ```--storage.tsdb.retention.size``` : 유지할 스토리지 블록의 최대 바이트 수. 오래된 데이터부터 제거하며 기본값은 0 또는 disable이다.
> 4. ```--storage.tsdb.retention : storage.tsdb.retention.time```에 의해 Deprecated 되었다.
> 5. ```--storage.tsdb.wal-compression``` :
> 즉, --storage.tsdb.retention.time을 prometheus 프로세스에 설정하도록 한다. 설정 방법은 [여기](https://passwd.tistory.com/entry/k8s-Prometheus-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%B4%EA%B4%80-%EA%B8%B0%EA%B0%84-%EC%84%A4%EC%A0%95)를 참조한다.

- 서비스가 정상적으로 실행됐는지 확인합니다.

```
 ss -antpl | grep 9090
```

![](image_3.9aba1312.png)





**11\. Harvest에서 정의한 Grafana 대시보드를 불러옵니다.**



**Grafana API key를** **생성합니다.**

```
curl -X POST -H "Content-Type: application/json" -d '{"name":"harvest", "role": "Admin"}' [http://admin:admin@localhost:3000/api/auth/keys](http://admin:admin@localhost:3000/api/auth/keys)
 {"id":3,"name":"harvest","key":"eyJrIjoidDBrdG83UlpBSGZhY0h5aVBTZlJLWG5ZZGhXYUtzbkoiLCJuIjoiaGFydmVzdCIsImlkIjoxfQ=="}
### Tips
## Grafana 10 version 부터는 api key에서 service account로 인증방식이 변경되기 때문에 harvest grafana import 명령을 사용할 수 없습니다. Harvest version ( 23.05)
5. ```--storage.tsdb.wal-compression``` :
cd /opt/harvest
bin/harvest grafana import --addr localhost:80(Grafana 포트)
```



명령어를 실행하면 아래와 같이 API 키를 받는 프롬프트가 나옵니다.

```
enter API token: <API Key> 
eyJrIjoiWlNsUGpJTmE3cHNwYWFUODFyZlVhdkRQaU9RdDVncUQiLCJuIjoiaGFydmVzdCIsImlkIjoxfQ==
```



이때 [https://netapp.github.io/harvest/dashboards/](https://netapp.github.io/harvest/dashboards/) 에 기재된 내용으로 API 키 만드는데 권한을 Editor 대신 Admin으로 생성합니다.



정상적으로 수행되면 Grafana에 미리 정의된 Dashboard 들어갑니다.





![](image_4.fd257c6b.png)





Grafana Data Source 추가하기

12. **Grafana Data Source 추가하기**



Grafana에서 왼쪽 아래 톱니바퀴에서 Data Sources 메뉴를 들어가서 Add Data Source 누릅니다.

![](image_5.44a641c0.png)



 URL [__http://<IP:Port__\>](http://%3cIP:Port%3e) 넣고 Save and Test 하면 끝.



![](image_6.39c9370b.png)



### 추가 메트릭 수집하기1(예제: EMS)

```cat /var/log/harvest/poller_tnas0102.log```



Harvest 22.08부터 제공되는 Metric 중, EMS가 있는데 로그를 들여다보면 수집은 되는데 ONTAP에서 Return되는게 없어서 수집되는 항목이 없는 것을 볼 수 있습니다.



![](image_7.75fcc127.jpg)



이는 ONTAP에 발생하고 있는 EMS 메시지가 없는것이 아니라 Harvest가 기본으로 대응되는 EMS 항목이 적어서 나타나는 모습이며 모든 EMS 메시지를 수집하기 위해서는 아래 절차를 거쳐 해결할 수 있습니다. 다른 방식도 유사하게 해결할 수 있습니다.



```cat /opt/harvest/conf/ems/9.6.0/ems.yaml```



모든 EMS를 대응하기 위해서는 먼저 어떤 EMS 메시지가 있는지 알아야 합니다.

```
curl --insecure --user admin:Netapp1!<Admin이나 접근 권한 있는 ID and PW> '[https://10.50.10.238<ONTAP](https://10.50.10.238%3cONTAP) IP Addr>/api/support/ems/messages?fields
```



위 명령어를 리눅스 서버에서 실행했을 때 아래와 같이 결과값이 나오는데 여기서 필요한 것은 `AccessCache.NearLimits`, `AccessCache.ReachedLimits` 와 같은 Name 입니다.

 `​`

이를 추출하기 위해 Notepad++ 등과 같은 에디터에서 다중 선택을 사용하면 쉽게 추출할 수 있습니다.



![](image_8.720ac0c3.jpg)





```vi /opt/harvest/conf/ems/9.6.0/ems.yaml```의 내용을 보면 ```name```과 ```export```가 있는데 ```name```은 앞전 API Call EMS 결과값에서 Name이랑 같고 ```export```는 어떤 값을 prometheus에 저장하느냐 인데, 이는 지정하기 나름입니다. ```Ems.yaml``` 예시처럼 별도로 지정해줘도 되며, 전체를 ```Prometheus```에 보내는 방법도 있습니다. 예제에는 전체를 보내는 방법을 사용합니다.

```bash
name:   EMS
query:  api/support/ems/events
object: ems

# default list of exports attached to each EMS event
exports:
  - message.name                            => message
  - node.name                               => node
  - node.uuid                               => node_uuid
  - message.severity                        => severity
  - index                                   => index

events:
  - name: AccessCache.NearLimits
  - name: AccessCache.ReachedLimits
  - name: CR.Data.File.Inaccessible
  - name: CR.Del.CrptStreamData.Fail
  - name: CR.Del.CrptStreamRedir.Fail
  - name: CR.Del.DangStreamData.Fail
  - name: CR.Del.DangStreamRedir.Fail
  - name: CR.Fix.Corrupt.Redir.Failed
  - name: CR.Fix.Crpt.Data.Dir.Failed
  - name: CR.Fix.Crpt.Data.File.Failed
  - name: CR.Fix.CrptStreamRedir.Fail
  - name: CR.Fix.Dang.Data.File.Failed
  - name: CR.Fix.Nlinks.Failed
  - name: CR.RDB.Counters.Not.Updated
  - name: CR.RDB.State.Not.Updated
  - name: CR.Redir.File.Inaccessible
  - name: CR.Snapshot.Not.Deleted
  - name: CR.Sync.ACL.Fail
  - name: LUN.SCSI.reservation.removal.failed
  - name: LUN.clone.log.full
  - name: LUN.clone.snapshot.deleted
  - name: LUN.copy.dstPresent
  - name: LUN.copy.started
  - name: LUN.create.nvfailed.volume
  - name: LUN.create.resized.base
  - name: LUN.data.unavailable
- name: LUN.destroy
…(중략)… 위와 같이 curl에서 나온 name 목록 전체를 추가합니다.

export_options:
  include_all_labels: true 
```



위처럼 지정하면 모든 EMS 메시지가 대응되고 Name, Severity, Index 가 포함되어 Prometheus로 Return 됩니다. 이를 적용하기 위해 Harvest를 Restart 합니다.

```bash
 /opt/harvest/bin/harvest restart 
```





![](image_9.2d23d16f.jpg)





그 후, Grafana에서 ems\_events Metric을 확인했을때 기존에 아무 값이 없었다면 이제는 위와 같이 확인할 수 있습니다.









## 추가 메트릭 수집하기2(예제: ZAPI)



ZAPI는 REST API 로 대체되기 전에 사용되던 API CALL 방식인데 22.08 기준으로 REST API 전환이 이뤄지는 중이며 아직 대부분의 메트릭을 ZAPI로 가져옵니다.

그 중, 성능 Detail Workload 메트릭을 수집할 수 있도록 완성이 돼있는데 Harvest는 Default로 이를 비활성화 했습니다.

Workload 메트릭이 수집 용량도 크고 모니터링 서버에 부하가 많이 가서 그런것으로 보입니다.



ONTAP:Volume 대시보드에서 Top Volume QoS Resource Latency Drilldown Dropdown을 보면 이미 Latency 관련해서 만들어진 패널들이 있는데 이는 Workload가 활성화 되야 볼 수 있습니다.

![](image_10.94bf94c6.jpg)



Workload를 활성화 하기 위해 아래와 같은 절차가 필요합니다.

```bash
 cd /opt/harvest/conf/zapiperf 
```



위 디렉토리에 가보면 아래와 같은 ```default.yaml```을 볼 수 있으며 아래는 해당 파일에 대한 설명입니다.

```bash
[root@localhost zapiperf]# cat default.yaml
collector:          ZapiPerf <- Collector 이름 

# Order here matters!
schedule:
  - counter: 1200s <- Counter(아래 Objects) 에 대한 정보를 기준시간마다 업데이트 
  - instance: 600s <- Instance (노드, 클러스터 기준) 를 기준시간마다 업데이트
  - data: 60s <- 아래 Performance data를 기준시간마다 업데이트 

objects:
  # Node-level metrics
  CIFSNode:               cifs_node.yaml 
  Disk:                   disk.yaml    <- Disk에 대한 정보를 가져오며 disk.yaml 파일(Template)에 어떻게 가져올 지에 대한 정의가 있음
  ExtCacheObj:            ext_cache_obj.yaml
  FCVI:                   fcvi.yaml
  FcpPort:                fcp.yaml
  HeadroomAggr:           resource_headroom_aggr.yaml
  HeadroomCPU:            resource_headroom_cpu.yaml
  HostAdapter:            hostadapter.yaml
  NFSv3Node:              nfsv3_node.yaml
  NFSv41Node:             nfsv4_1_node.yaml
  NFSv42Node:             nfsv4_2_node.yaml
  NFSv4Node:              nfsv4_node.yaml
  NVMfLif:                nvmf_lif.yaml
  Namespace:              namespace.yaml
  NicCommon:              nic_common.yaml
  ObjectStoreClient:      object_store_client_op.yaml
  Path:                   path.yaml
  Qtree:                  qtree.yaml
  SystemNode:             system_node.yaml
  TokenManager:           token_manager.yaml
  VolumeNode:             volume_node.yaml
  WAFL:                   wafl.yaml
  WAFLAggr:               wafl_hya_per_aggr.yaml
  WAFLSizer:              wafl_hya_sizer.yaml
#  NFSv4Pool:              nfsv4_pool.yaml

  # SVM-level metrics
  CIFSvserver:            cifs_vserver.yaml
  CopyManager:            copy_manager.yaml
  FcpLif:                 fcp_lif.yaml
  ISCSI:                  iscsi_lif.yaml
  LIF:                    lif.yaml
  LUN:                    lun.yaml
  NFSv3:                  nfsv3.yaml
  NFSv41:                 nfsv4_1.yaml
  NFSv42:                 nfsv4_2.yaml
  NFSv4:                  nfsv4.yaml
  Volume:                 volume.yaml
  VolumeSvm:              volume_svm.yaml
  WAFLCompBin:            wafl_comp_aggr_vol_bin.yaml
  Vscan:                  vscan.yaml
  VscanSVM:               vscan_svm.yaml

#  Uncomment to collect workload/QOS counters
#  Workload:               workload.yaml <- 해당 열 앞에 주석처리 #을 지우면 활성화 됩니다.
#  WorkloadDetail:         workload_detail.yaml
#  WorkloadVolume:         workload_volume.yaml
#  WorkloadDetailVolume:   workload_detail_volume.yaml
```



필요한 내용을 수정하고 저장하고 Harvest를 재시작하면 해당 Workload가 수집되는 것을 log 또는 Grafana 에서 볼 수 있습니다.

반영이 안된다면 schedule 시간이 길어 해당 cycle이 도달하지 않아 그럴 수도 있습니다. 10분 정도 기다리면 나와야 합니다.





![](image_11.40ae2b05.jpg)





위처럼 활성화 된 것을 볼 수 있습니다.



> #### 주의사항!
> ![](image_12.17c246ed.jpg)
> 위에서 활성화 한 EMS와 ZapiPerf:WorkloadDetail에 대한 내용인데 보이는 것처럼 API Call time이 엄청나게 깁니다.
> (보통은 100ms 이하) 이로 인해 모니터링 서버에 부하가 심해질 수 있으므로 필요한 부분만 하던지 수집 빈도를 적당하게 늘려야 합니다.



### 추가 메트릭 수집하기3 (예제: QoS)

QoS는 위 Workload Detail을 활성화하면서 대부분의 성능 메트릭(Throughput, Latency, IOPS 등)이 활성화되는데 설정값에 대한 메트릭은 활성화되지 않습니다.

예를 들어,

현재 IOPS는 알 수 있지만 QoS Max Throughput을 얼마에 걸어놨는지 알 수 없습니다.

이러한 설정값을 Label이라 하는데 이를 받아오기 위해서 Template를 직접 만들어야 합니다.



```/opt/harvest/conf/zapi/default.yaml```을 보면 QoS 관련 내용이 없다. 아래처럼 추가합니다.





![](image_13.472cf7e7.jpg)





알파벳 순서에 맞게 넣는것이 중요하다고 합니다. NtpServer 아래 QoSLimit을 추가하고 저장합니다.



중간에 9.8.0 버전은 ONTAP 버전의 기준입니다. 예를 들어 Template폴더에 동일한 버전의 ONTAP이 있으면 해당 내용을 사용하고, 없으면 하위 호환으로 사용합니다.

(관련 문서: [https://github.com/NetApp/harvest/blob/main/docs/configure-templates.md#harvest-versioned-templates](https://github.com/NetApp/harvest/blob/main/docs/configure-templates.md#harvest-versioned-templates))





![](image_14.3365d946.jpg)





QoS는 ONTAP 9.9.0 이후에 생긴것이 아니므로 9.8.0에 추가합니다.



`/opt/harvest/conf/zapi/cdot/9.8.0/`에 가보면 이미 정의된 Template이 있는데 여기에 `qoslimit.yaml`을 아래 내용으로 만듭니다.



```bash
 vi /opt/harvest/conf/zapi/cdot/9.8.0/qoslimit.yaml
```

```yaml
<주석 없는 버전>
name: QoSLimit
query: qos-policy-group-get-iter
object: qos

collect_only_labels: true

counters:
  qos-policy-group-info:
    - ^policy-group => policy_group
    - ^^vserver => svm
    - ^^pgid
    - ^policy-group-class => policy_group_class
    - ^max-throughput => max_throughput
    - ^min-throughput => min_throughput
    - ^num-workloads => num_workloads

plugins:
  - LabelAgent:
    value_to_num:
      - status status up 0
    split:
      - max_throughput `IOPS` max_num,placeholder

export_options:
  instance_labels:
    - svm
    - max_throughput
    - min_throughput
    - num_workloads
    - max_num
  instance_keys:
    - policy_group
```



```yaml
<주석 포함>
name: QoSLimit <- Template 이름
query: qos-policy-group-get-iter <- 해당 Template이 사용하는 API Call 이름
object: qos <- API Call의 Object

collect_only_labels: true <- Label(설정값 등) 만 가져오기

counters:
  qos-policy-group-info:
    - ^policy-group => policy_group <- ^는 Label로 저장.
    - ^^vserver => svm <- ^^는 Label이면서 Instance Key로 저장. Key는 카운터를 구분할 때 사용.
    - ^^pgid
    - ^policy-group-class => policy_group_class <- =>는 policy-group-class 라는 이름 대신 policy_group_class로 저장
    - ^max-throughput => max_throughput
    - ^min-throughput => min_throughput
- ^num-workloads => num_workloads 
플러그인 관련문서: https://github.com/NetApp/harvest/blob/24e4c2b20d7307695f57e614301fb70f35caae90/docs/plugins.md#built-in-plugins

plugins: 
  - LabelAgent:
    value_to_num:
      - status status up 0
    split:
      - max_throughput `IOPS` max_num,placeholder 

 
export_options:
  instance_labels:
    - svm
    - max_throughput
    - min_throughput
    - num_workloads
    - max_num
  instance_keys:
    - policy_group
```

위는 ```qos-policy-group-info```로 받아 온 ```max_throughput```을 처리하는 부분인데, ONTAP에 보면 max throughput을 IOPS로 지정할 수도 있고 bit per sec, byte per sec 등으로 저장할 수 있습니다.

해당 예시의 경우 IOPS로만 설정하는 경우인데 ONTAP에서 4000IOPS라고 max throughput을 지정하면 그대로 4000IOPS를 API Call에서 반환하게 됩니다.

그러나 Grafana 자체 기능에는 String 처럼 숫자, 문자 합쳐진 데이터가 들어오는 경우 해당 값을 정렬하거나 기준으로 삼아 계산할 수 없기 때문에 이를 분리하는 작업이 필요합니다.



이를 위해 사용한 플러그인은 \`\`\`split\`\`\`으로, 첫번째는 분리할 값, 두번째는 분리할 기준, 세번째는 분리한 앞부분, 네번째는 뒷부분이라고 생각하시면 됩니다.

앞의 예시로 4000IOPS가 설정값이면 max_num에 4000이 저장되고 placeholder에 IOPS가 저장됩니다. 그럼 Grafana에서는 max_num을 보고 계산을 하면 됩니다.

```json

export_options:
  instance_labels:
    - svm
    - max_throughput
    - min_throughput
    - num_workloads
    - max_num
  instance_keys:
    - policy_group

위 내용은 API Call 했을 때 어느 label과 key를 포함하는 지에 대한 내용입니다.
```

### 추가 메트릭 수집하기 4 (예제: ONTAP Management SDK 참조 개발)

추가 메트릭 수집하기 1과 유사한 방식이지만 본 예시는 ZAPI(ONTAPI)를 활용하는 방식입니다.

예시로 기존에 수집되지 않는 성능 데이터를 가져오는 것을 아래를 통해 만들 수 있습니다.



[https://mysupport.netapp.com/documentation/docweb/index.html?productID=63638&language=en-US](https://mysupport.netapp.com/documentation/docweb/index.html?productID=63638&language=en-US)



위 사이트에 접속하면 Reference Manual for ONTAP 9.XX APIs 라는 PDF 문서를 찾을 수 있습니다.

사용하고자 하는 ONTAP 버전(버전은 하위호환)을 기준으로 문서를 다운받습니다. 본 예시에서는 Reference Manual for ONTAP 9.8 APIs문서를 기준하고 있습니다.

해당 문서 20페이지, ONTAPI Catalog에서 가져오고자 하는 메트릭을 찾습니다. 예시에서는 ha-interconnect의 상태를 확인하는 API를 활용합니다.



ZAPI에서 주로 상태를 확인하는 API의 이름은 노드 상태를 확인하는 `system-node-get-ite`r, 센서를 확인하는 `environment-sensors-get-iter`, NTP 서버의 설정을 확인하는 `ntp-server-get-iter` 처럼 get-iter 로 끝납니다. HA Interconnect 또한 get-iter를 가지고 있습니다. API 문서 20페이지의 ha-interconnect를 타고 가면 카탈로그는 아래와 같습니다.

![](image_15.00bca4bf.png)

여기서 여러 정보를 가지고 올 수 있으며 예시에서는 ```ha-interconnectconnection-status-get-iter``` 를 사용합니다.

![](image_16.dd1ecab0.png)

```ha-interconnectconnection-status-get-iter```가 query의 이름이며 아래는 해당 desired-attributes는 해당 쿼리가 반환하는 데이터의 목록을 볼 수 있습니다.

![](image_17.3f1a8238.png)



… 중략 …



여기서 link-status와 node-name을 가져와 현재 HA Interconnect 상태를 확인할 수 있는 메트릭을 불러올 수 있도록 아래와 같이 작성합니다.

```yaml
name:       HAInterconnectStatus
query:      ha-interconnect-connection-status-get-iter
object:     hainterconnect
 
counters:
  ha-interconnect-status-info:
    - ^^node-name         => node
    - ^link-status
    - port1-datarate
    - port2-datarate
 
plugins:
  - LabelAgent:
    value_to_num:
      - ha_status link-status up up `1`
 
export_options:
  include_all_labels: true
```



위 counters 부분에서 ```^^```는 Key값으로 사용하는 instance를 정의합니다. 이는 다른 카운터와 구분하기 위한 값으로 사용됩니다.

```^```는 Value라고 보시면 됩니다.



Plugin 에서 value\_to\_num에 대한 설명은 아래 플러그인 페이지에 상세히 기재돼있습니다.

[https://github.com/NetApp/harvest/blob/24e4c2b20d7307695f57e614301fb70f35caae90/docs/plugins.md#built-in-plugins](https://github.com/NetApp/harvest/blob/24e4c2b20d7307695f57e614301fb70f35caae90/docs/plugins.md#built-in-plugins)__’__



이와 같이 작성 후 `/opt/harvest/conf/zapi/cdot/9.8.0/ha_status.yaml` 에 저장합니다.

그 후, ZAPI 컬렉터 Config 파일을 수정해야 합니다. /opt/harvest/conf/zapi/default.yaml에 아래에 `HAInterconnectStatus: ha_status.yaml` 추가하고 저장합니다.

```yaml
collector:          Zapi

# Order here matters!
schedule:
  - instance: 600s
  - data: 180s

objects:
  Aggregate:                   aggr.yaml
  AggregateEfficiency:         aggr_efficiency.yaml
  ClusterPeer:                 clusterpeer.yaml
  Disk:                        disk.yaml
==HAInterconnectStatus: ha_status.yaml==
```



Default.yaml과 작성한 템플릿을 저장하고 harvest restart을 합니다.



정상적으로 수집되는 것을 확인하기 위해 아래 명령어를 입력하면 아래와 같은 로그 메시지를 확인할 수 있습니다.

```bash
cat /var/log/harvest/poller_tnas0102.log | grep HA

{"level":"info","Poller":"tnas0102","collector":"Zapi:HAInterconnectStatus","path":"conf/zapi/cdot/9.8.0/ha_status.yaml","v":"9.9.1","caller":"collector/helpers.go:133","time":"2022-11-20T20:37:38+09:00","message":"best-fit template"}
{"level":"info","Poller":"tnas0102","collector":"Zapi:HAInterconnectStatus","instances":2,"metrics":2,"apiD":"220ms","parseD":"0s","caller":"collector/zapi.go:443","time":"2022-11-20T20:37:41+09:00","message":"Collected"}
```



또한 Prometheus와 Grafana에서 쿼리를 입력하면 결과를 확인할 수 있습니다. 쿼리의 이름은 object 이름 \+ value\_to\_num의 첫번째 키워드이며 이는 플러그인, 템플릿, Collector에 따라 달라질 수 있습니다.



![](image_18.4c861038.jpg)





플러그인에서 Up일 경우 1을 반환하도록 처리했으므로 이를 활용해 Grafana에서 값이 1일때 상태가 정상임을 표시하는 패널을 만들 수 있습니다.





![](image_19.fcd52217.png)







## 추가 설정 -  Grafana SMTP 추가하기

그라파나 알럿 설정 시 Slack을 통한 알럿 전달도 좋지만 메일도 해두면 편하겠죠?

먼저 그라파나 시스템에서 메일을 보내기 위해선 Outlook과 같은 SMTP클라이언트가 필요합니다.

> ### Tips
> 메일 서버 구조를 잘 모르시는 분을 위한 간단한 메일 서버 통신 구조 설명
> ![](image_20.4fee7d6e.png)
> 

그라파나 SMTP 설정

1. 그라파나 SMTP 설정

```
Vim /etc/grafana/grafana.ini
```

```
#################################### SMTP / Emailing ##########################
[smtp]
enabled = true
host = smtp.google.com:587
user = wyahn1219@gmail.com
# If the password contains # or ; you have to wrap it with triple quotes. Ex """#password;"""
password = sandeul12!(
;cert_file =
;key_file =
;skip_verify = false
from_address = wyahn1219@gmail.com
from_name = Grafana
```


### 추가 설정 – 데이터 불러오는 주기 조정하기

성능 수치 같은 경우 실시간으로 변동되는 수치로 인해 분석이 필요한 경우 성능 수치를 빠른 간격으로 받아야 하는 경우가 있습니다.

성능 제약사항으로 인해 기본값으로 60초에 한번 수집하도록 잡혀있지만 이를 1초까지 당길 수 있습니다.

먼저 ```/opt/harvest/conf/zapiperf/default.yaml```을 열어 아래와 같이 data의 값을 원하는 주기로 변경합니다.

```​data: 1s​```

```yaml
collector:          ZapiPerf

# Order here matters!
schedule:
  - counter: 1200s
  - instance: 600s
  - data: 1s
```

그리고 Grafana에서 대시보드를 열면 기본값으로 설정할 수 있는 최소 Refresh Minimum이 10초로 설정되있습니다. 이를 낮추기 위해 config 변경이 필요합니다.

```vi /etc/grafana/grafana.ini``` 를 열어 [Dashboards] 아래  ​min_refresh_interval = 1s​  를 추가 후 저장합니다.

```ini
#################################### Dashboards History ##################
[dashboards]
# Number dashboard versions to keep (per dashboard). Default: 20, Minimum: 1
;versions_to_keep = 20

# Minimum dashboard refresh interval. When set, this will restrict users to set the refresh interval of a dashboard lower than given interval. Per default this is 5 seconds.
# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.
;min_refresh_interval = 5s

# Path to the default home dashboard. If this value is empty, then Grafana uses StaticRootPath + "dashboards/home.json"
;default_home_dashboard_path =
​min_refresh_interval = 1s
#################################### Users ###############################
```

```bash
systemctl daemon-reload
systemctl stop grafana-server.service
systemctl start grafana-server
```



==서비스를 재시작 합니다.==



==그리고 대시보드 설정에 들어가 Auto refresh에 10s 앞에 원하는 값(1s, 5s)를 추가합니다.==





![](image_21.f8d12952.jpg)









![](image_22.593bce67.jpg)







![](image_23.bbb830aa.jpg)

우측 상단 Refresh Dropdown에서 1초와 5초가 추가된 것을 확인할 수 있습니다.

```Default.yaml```과 Grafana 새로고침 주기를 1초로 설정했음에도 불구하고 15초에 한번씩 데이터가 들어오는 것을 볼 수 있습니다.

이는 Prometheus가 Harvest에서 가져오는 주기를 아직 수정하지 않아 15초로 잡혀 있습니다.

![](image_24.53b122f0.png)

이를 수정하기 위해  ​```/etc/prometheus/prometheus.yml```​ 에서  ​ ​```scrape_interval```​ ​ 을 아래와 같이 추가하고 저장합니다.

```scrape_interval: 1s```

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 1s
    static_configs:
      - targets: ['localhost:9001']

systemctl restart prometheus 
```



완료하면 아래와 같이 Interval이 바뀐것을 확인할 수 있습니다.





![](image_25.9064875c.png)





그리고 Grafana가 Prometheus로 부터 가져오는 Interval도 조정해야 합니다.

Grafana 설정 – Data Source – Prometheus – Scrape Interval을 1s로 입력하고 저장합니다.





![](image_26.bd3179f2.png)





위 설정까지 마치면 일반적인 패널은 1초에 한번씩 업데이트 되는 것을 확인할 수 있지만, 앞전에 Workload로 수집을 활성화한 패널들은 1초에 한번 업데이트가 안되는 것을 볼 수 있습니다. 이는 Workload 템플릿에는 별도로 Schedule 사이클이 지정되어 있으므로 나타나며,

/opt/harvest/conf/zapiperf/cdot/9.8.0 에서 workload로 시작하는 4개의 템플릿에서 Schedule 아래 Data를 원하는 사이클로 조정하고 저장 후 서비스를 재시작하면 적용되는 것을 볼 수 있습니다.



### 추가 설정 – 시간 맞추기

Grafana 서버의 시간과 ONTAP의 시간이 달라서 오차 발생 가능성이 있고 아니면 Timezone이 달라서 시간이 크게 다를 수도 있으니 이를 확인하시기 위해 각 서버의 time을 일치시키시기 바랍니다.

```bash
date -s "$(wget --method=HEAD -qSO- --max-redirect=0 google.com 2>&1 | grep Date: | cut -d' ' -f2-7)"
timedatectl set-timezone Asia/Seoul
```

### 추가 설정 – 보안 인증서

Prometheus와 Grafana에서 Web Interface 및 통신을 위한 보안 인증서 사용을 지원하며 선택에 따라 사용 할 수 있습니다. (기본 비활성화)

그리고 Thanos Querier의 IP와 포트(HTTP)를 Grafana에서 기존 Prometheus 대신 Data Source로 사용하면 됩니다.

아래 사이트에서 여러 시나리오를 테스트 할 수 있으므로 참고하시기 바랍니다.

https://killercoda.com/thanos

## 참고사항

NABOX를 사용하는 경우 /opt/harvest 경로 대신 /opt/packages/harvest2 경로입니다.

> ## Reference
> - Harvest 관련 문서 목록: https://github.com/NetApp/harvest/tree/main/docs
> - Harvest 질문 커뮤니티: https://discord.com/channels/855068651522490400/1001963189124206732
> - Grafana 테스트 및 패널 샘플 사이트: https://play.grafana.org/d/000000012/grafana-play-home?orgId=1
> - Prometheus Query Basics: https://prometheus.io/docs/prometheus/latest/querying/basics/
> - Prometheus API: https://prometheus.io/docs/guides/tls-encryption/
> - Prometheus 웹 인터페이스: https://prometheus.io/docs/prometheus/latest/configuration/https/
> - Grafana 웹 인터페이스: https://medium.com/grafana-tutorials/adding-ssl-to-grafana-eb4ab634e43f
> - Harvest SSL: https://github.com/NetApp/harvest/blob/17f3490f37ee50847d618f7f0459344792bf34bb/docs/configure-harvest-basic.md


## CentOS 초기설정

IP 설정 / DNS 추가

```
vi /etc/sysconfig/network-scripts/ifcfg-ens33 
```

```
PREFIX=16
IPADDR=10.50.10.247
GATEWAY=10.50.0.1
DNS1=8.8.8.8
```

위 내용 추가하고 BOOTPROTO='none' 변경

```
systemctl restart network
```





